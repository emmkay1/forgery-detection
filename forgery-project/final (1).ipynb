{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.4.1-cp37-cp37m-manylinux1_x86_64.whl (10.3 MB)\n",
      "Collecting keract\n",
      "  Using cached keract-4.4.0-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/site-packages (from matplotlib) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/site-packages (from matplotlib) (7.2.0)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Installing collected packages: kiwisolver, cycler, matplotlib, keract\n",
      "Successfully installed cycler-0.10.0 keract-4.4.0 kiwisolver-1.3.1 matplotlib-3.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib keract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 17 07:40:21 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   50C    P0    21W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Input\n",
    "# import tf_slim as slim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# import keract\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import itertools\n",
    "import random\n",
    "%matplotlib inline\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SRM(imgs):\n",
    "    filter1 = [[0, 0, 0, 0, 0],\n",
    "               [0, -1, 2, -1, 0],\n",
    "               [0, 2, -4, 2, 0],\n",
    "               [0, -1, 2, -1, 0],\n",
    "               [0, 0, 0, 0, 0]]\n",
    "    filter2 = [[-1, 2, -2, 2, -1],\n",
    "               [2, -6, 8, -6, 2],\n",
    "               [-2, 8, -12, 8, -2],\n",
    "               [2, -6, 8, -6, 2],\n",
    "               [-1, 2, -2, 2, -1]]\n",
    "    filter3 = [[0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0],\n",
    "               [0, 1, -2, 1, 0],\n",
    "               [0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0]]\n",
    "    q = [4.0, 12.0, 2.0]\n",
    "    filter1 = np.asarray(filter1, dtype=float) / 4\n",
    "    filter2 = np.asarray(filter2, dtype=float) / 12\n",
    "    filter3 = np.asarray(filter3, dtype=float) / 2\n",
    "    filters = [[filter1, filter1, filter1], [filter2, filter2, filter2], [filter3, filter3, filter3]]\n",
    "    filters = np.einsum('klij->ijlk', filters)\n",
    "    filters = tf.Variable(filters, dtype=tf.float32)\n",
    "    imgs = np.array(imgs, dtype=float)\n",
    "    input = tf.Variable(imgs, dtype=tf.float32)\n",
    "    op = tf.nn.conv2d(input, filters, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "    q = [4.0, 12.0, 2.0]\n",
    "    filter1 = [[0, 0, 0, 0, 0],\n",
    "            [0, -1, 2, -1, 0],\n",
    "            [0, 2, -4, 2, 0],\n",
    "            [0, -1, 2, -1, 0],\n",
    "            [0, 0, 0, 0, 0]]\n",
    "    filter2 = [[-1, 2, -2, 2, -1],\n",
    "            [2, -6, 8, -6, 2],\n",
    "            [-2, 8, -12, 8, -2],\n",
    "            [2, -6, 8, -6, 2],\n",
    "            [-1, 2, -2, 2, -1]]\n",
    "    filter3 = [[0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0],\n",
    "            [0, 1, -2, 1, 0],\n",
    "            [0, 0, 0, 0, 0],\n",
    "            [0, 0, 0, 0, 0]]\n",
    "    filter1 = np.asarray(filter1, dtype=float) / q[0]\n",
    "    filter2 = np.asarray(filter2, dtype=float) / q[1]\n",
    "    filter3 = np.asarray(filter3, dtype=float) / q[2]\n",
    "    filters = [[filter1, filter1, filter1], [filter2, filter2, filter2], [filter3, filter3, filter3]]\n",
    "    filters = np.einsum('klij->ijlk', filters)\n",
    "    filters = filters.flatten()\n",
    "    imgs = np.array(imgs, dtype=float)\n",
    "    input = tf.Variable(imgs, dtype=tf.float32)\n",
    "    initializer_srm = tf.constant_initializer(filters)\n",
    "    def truncate_2(x):\n",
    "        neg = ((x + 2) + abs(x + 2)) / 2 - 2\n",
    "        return -(-neg+2 + abs(- neg+2)) / 2 + 2\n",
    "    op2 = slim.conv2d(input, 3, [5, 5], trainable=False, weights_initializer=initializer_srm, activation_fn=None, padding='SAME', stride=1, scope='srm')\n",
    "    op2 = truncate_2(op2)\n",
    "\n",
    "    res = np.round(op[0])\n",
    "    res[res > 2] = 2\n",
    "    res[res < -2] = -2\n",
    "\n",
    "    ress = np.array([res], dtype=float)\n",
    "    ress2 = np.array(op2, dtype=float)\n",
    "    return ress2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializer():\n",
    "    # q = [4.0, 12.0, 2.0]\n",
    "    # filter1 = [[0, 0, 0, 0, 0],\n",
    "    #         [0, -1, 2, -1, 0],\n",
    "    #         [0, 2, -4, 2, 0],\n",
    "    #         [0, -1, 2, -1, 0],\n",
    "    #         [0, 0, 0, 0, 0]]\n",
    "    # filter2 = [[-1, 2, -2, 2, -1],\n",
    "    #         [2, -6, 8, -6, 2],\n",
    "    #         [-2, 8, -12, 8, -2],\n",
    "    #         [2, -6, 8, -6, 2],\n",
    "    #         [-1, 2, -2, 2, -1]]\n",
    "    # filter3 = [[0, 0, 0, 0, 0],\n",
    "    #         [0, 0, 0, 0, 0],\n",
    "    #         [0, 1, -2, 1, 0],\n",
    "    #         [0, 0, 0, 0, 0],\n",
    "    #         [0, 0, 0, 0, 0]]\n",
    "    # filter1 = np.asarray(filter1, dtype=float) / q[0]\n",
    "    # filter2 = np.asarray(filter2, dtype=float) / q[1]\n",
    "    # filter3 = np.asarray(filter3, dtype=float) / q[2]\n",
    "    # filters = [[filter1, filter1, filter1], [filter2, filter2, filter2], [filter3, filter3, filter3]]\n",
    "    # filters = np.einsum('klij->ijlk', filters)\n",
    "    # filters = filters.flatten()\n",
    "    # initializer_srm = tf.constant_initializer(filters)\n",
    "\n",
    "    filter1 = [[0, 0, 0, 0, 0],\n",
    "               [0, -1, 2, -1, 0],\n",
    "               [0, 2, -4, 2, 0],\n",
    "               [0, -1, 2, -1, 0],\n",
    "               [0, 0, 0, 0, 0]]\n",
    "    filter2 = [[-1, 2, -2, 2, -1],\n",
    "               [2, -6, 8, -6, 2],\n",
    "               [-2, 8, -12, 8, -2],\n",
    "               [2, -6, 8, -6, 2],\n",
    "               [-1, 2, -2, 2, -1]]\n",
    "    filter3 = [[0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0],\n",
    "               [0, 1, -2, 1, 0],\n",
    "               [0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0]]\n",
    "    filter1 = np.asarray(filter1, dtype=float) / 4\n",
    "    filter2 = np.asarray(filter2, dtype=float) / 12\n",
    "    filter3 = np.asarray(filter3, dtype=float) / 2\n",
    "    filters = [[filter1, filter1, filter1], [filter2, filter2, filter2], [filter3, filter3, filter3]]\n",
    "    filters = np.einsum('klij->ijlk', filters)\n",
    "    filters = tf.Variable(filters, dtype=tf.float32)\n",
    "    return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 224\n",
    "w = 224\n",
    "image_size = (h, w)\n",
    "\n",
    "# np_arr = lambda img: img.resize(image_size).flatten() / 255.0\n",
    "np_arr = lambda img: np.array(img.resize(image_size)).flatten() / 255.0\n",
    "\n",
    "def prepare_image(image_path):\n",
    "    # img = Image.open(image_path)\n",
    "    # img = img.resize(image_size)\n",
    "    # img = np.asarray(img)\n",
    "    # imgs = np.array(img, dtype=float)\n",
    "    # input = tf.Variable(imgs, dtype=tf.float32)\n",
    "    return np_arr(Image.open(image_path))\n",
    "    # SRM([img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = prepare_image('./example_images/Tp_D_CNN_S_O_nat10153_ani00097_12135.jpg')\n",
    "# img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = Image.open('Tp_D_NNN_M_N_pla10121_cha00027_11669.jpg')\n",
    "# # img = np.asarray(img)\n",
    "# img = img.resize(image_size)\n",
    "# img = np.asarray(img) /255.0\n",
    "# img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat = prepare_image('./example_images/Tp_D_CNN_S_O_nat10153_ani00097_12135.jpg')\n",
    "# plt.imshow(cat[0])\n",
    "# # plt.show()\n",
    "# plt.axis('off')\n",
    "# plt.savefig(\"srm.png\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # SRM converted images\n",
    "Y = [] # 0 for fake, 1 for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(path, cls):\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('jpg') or filename.endswith('png'):\n",
    "                try:\n",
    "                    full_path = os.path.join(dirname, filename)\n",
    "                    X.append(prepare_image(full_path))\n",
    "                    Y.append(cls)\n",
    "                except:\n",
    "                    pass\n",
    "                if len(Y) % 500 == 0:\n",
    "                    print('Processing {} images'.format(len(Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 500 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:766: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 2. Skipping tag 41487\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n",
      "/usr/local/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:766: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 41988\n",
      "  \" Skipping tag %s\" % (size, len(data), tag)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1000 images\n",
      "Processing 1500 images\n",
      "Processing 2000 images\n",
      "Processing 2500 images\n",
      "Processing 3000 images\n",
      "Processing 3500 images\n",
      "Processing 4000 images\n",
      "Processing 4500 images\n",
      "Processing 5000 images\n"
     ]
    }
   ],
   "source": [
    "#place authentic\n",
    "Au_path = 'forgery/data/Au'\n",
    "prepare_data(Au_path, 1)\n",
    "random.shuffle(X)\n",
    "X = X[:2100]\n",
    "Y = Y[:2100]\n",
    "print(len(X), len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2500 images\n",
      "Processing 3000 images\n",
      "Processing 3500 images\n",
      "Processing 4000 images\n",
      "4164 4164\n"
     ]
    }
   ],
   "source": [
    "#place tampered\n",
    "Tp_path = 'forgery/data/Tp'\n",
    "prepare_data(Tp_path, 0)\n",
    "print(len(X), len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = to_categorical(Y, 2)\n",
    "X = X.reshape(-1, h, w, 3)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size = 0.2, random_state=5)\n",
    "\n",
    "X = X.reshape(-1,1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_2(x):\n",
    "    neg = ((x + 2) + abs(x + 2)) / 2 - 2\n",
    "    return -(-neg+2 + abs(- neg+2)) / 2 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer_srm = initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_srm-layer_6 (Ten [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 224, 224, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 224, 224, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 112, 112, 128)     512       \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 112, 112, 128)     512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_78 (Batc (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_79 (Batc (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_80 (Batc (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               51380736  \n",
      "_________________________________________________________________\n",
      "batch_normalization_81 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 61,389,378\n",
      "Trainable params: 61,383,106\n",
      "Non-trainable params: 6,272\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(h,w,3))\n",
    "op = tf.nn.conv2d(input, initializer_srm, strides=[1, 1, 1, 1], padding='SAME', name='srm-layer')\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(op)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D(padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D(padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(256, 3, activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(256, 3, activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(256, 3, activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D(padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(512, 3, activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(512, 3, activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(512, 3, activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D(padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(512, 3, activation='relu', padding='same')(x)\n",
    "x = Conv2D(512, 3, activation='relu', padding='same')(x)\n",
    "x = Conv2D(512, 3, activation='relu', padding='same')(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "# x = BatchNormalization()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 32\n",
    "init_lr = 1e-4\n",
    "optimizer = Adam(lr = init_lr, decay = init_lr/epochs)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_acc', min_delta=0,patience=2, verbose=0, mode='auto')\n",
    "\n",
    "checkpoint_filepath = 'tmp/checkpoint'\n",
    "model_checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True, monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "  2/105 [..............................] - ETA: 19s - loss: 1.0746 - accuracy: 0.6562WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1158s vs `on_train_batch_end` time: 0.2645s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1158s vs `on_train_batch_end` time: 0.2645s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - ETA: 0s - loss: 0.7348 - accuracy: 0.5965WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 51s 484ms/step - loss: 0.7348 - accuracy: 0.5965 - val_loss: 0.7011 - val_accuracy: 0.4886\n",
      "Epoch 2/30\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.5682 - accuracy: 0.7229WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 51s 484ms/step - loss: 0.5682 - accuracy: 0.7229 - val_loss: 0.7664 - val_accuracy: 0.5114\n",
      "Epoch 3/30\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.4338 - accuracy: 0.8187WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 51s 482ms/step - loss: 0.4338 - accuracy: 0.8187 - val_loss: 0.6889 - val_accuracy: 0.5318\n",
      "Epoch 4/30\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.3987 - accuracy: 0.8547WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 51s 482ms/step - loss: 0.3987 - accuracy: 0.8547 - val_loss: 0.6788 - val_accuracy: 0.5786\n",
      "Epoch 5/30\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.3257 - accuracy: 0.8901WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 44s 417ms/step - loss: 0.3257 - accuracy: 0.8901 - val_loss: 0.7782 - val_accuracy: 0.5402\n",
      "Epoch 6/30\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.3138 - accuracy: 0.8997WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 45s 426ms/step - loss: 0.3138 - accuracy: 0.8997 - val_loss: 1.5357 - val_accuracy: 0.5246\n",
      "Epoch 7/30\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.2798 - accuracy: 0.9114WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 52s 496ms/step - loss: 0.2798 - accuracy: 0.9114 - val_loss: 0.8100 - val_accuracy: 0.6351\n",
      "Epoch 8/30\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.2240 - accuracy: 0.9307WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 51s 481ms/step - loss: 0.2240 - accuracy: 0.9307 - val_loss: 0.7548 - val_accuracy: 0.6735\n",
      "Epoch 9/30\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.2019 - accuracy: 0.9469WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 50s 480ms/step - loss: 0.2019 - accuracy: 0.9469 - val_loss: 0.7863 - val_accuracy: 0.7323\n",
      "Epoch 10/30\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.2518 - accuracy: 0.9243WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 43s 412ms/step - loss: 0.2518 - accuracy: 0.9243 - val_loss: 1.2361 - val_accuracy: 0.5474\n",
      "Epoch 11/30\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.2285 - accuracy: 0.9358WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 51s 488ms/step - loss: 0.2285 - accuracy: 0.9358 - val_loss: 0.7336 - val_accuracy: 0.7359\n",
      "Epoch 12/30\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.1655 - accuracy: 0.9583WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 52s 496ms/step - loss: 0.1655 - accuracy: 0.9583 - val_loss: 0.7407 - val_accuracy: 0.7479\n",
      "Epoch 13/30\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.1570 - accuracy: 0.9637WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 44s 422ms/step - loss: 0.1570 - accuracy: 0.9637 - val_loss: 1.0733 - val_accuracy: 0.5462\n",
      "Epoch 14/30\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.9706WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 43s 412ms/step - loss: 0.1423 - accuracy: 0.9706 - val_loss: 0.8023 - val_accuracy: 0.7311\n",
      "Epoch 15/30\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.1569 - accuracy: 0.9673WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 43s 408ms/step - loss: 0.1569 - accuracy: 0.9673 - val_loss: 1.0380 - val_accuracy: 0.5930\n",
      "Epoch 16/30\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.1174 - accuracy: 0.9751WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 43s 411ms/step - loss: 0.1174 - accuracy: 0.9751 - val_loss: 1.0987 - val_accuracy: 0.5690\n",
      "Epoch 17/30\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.1267 - accuracy: 0.9757WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 44s 416ms/step - loss: 0.1267 - accuracy: 0.9757 - val_loss: 0.7338 - val_accuracy: 0.7275\n",
      "Epoch 18/30\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.1117 - accuracy: 0.9787WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 44s 421ms/step - loss: 0.1117 - accuracy: 0.9787 - val_loss: 1.1160 - val_accuracy: 0.6158\n",
      "Epoch 19/30\n",
      " 34/105 [========>.....................] - ETA: 27s - loss: 0.0731 - accuracy: 0.9881"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val), callbacks=[early_stopping, model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5d1fe10610>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = np.array(Image.open('cat.jpg').resize(image_size)).flatten() / 255.0\n",
    "cat = cat.reshape(-1, 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = keract.get_activations(model, cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 (1, 224, 224, 3) \n",
      "tf_op_layer_srm-layer (1, 224, 224, 3) \n",
      "conv2d (1, 224, 224, 64) \n",
      "batch_normalization (1, 224, 224, 64) \n",
      "conv2d_1 (1, 224, 224, 64) \n",
      "batch_normalization_1 (1, 224, 224, 64) \n",
      "max_pooling2d (1, 112, 112, 64) \n",
      "batch_normalization_2 (1, 112, 112, 64) \n",
      "conv2d_2 (1, 112, 112, 128) \n",
      "batch_normalization_3 (1, 112, 112, 128) \n",
      "conv2d_3 (1, 112, 112, 128) \n",
      "batch_normalization_4 (1, 112, 112, 128) \n",
      "max_pooling2d_1 (1, 56, 56, 128) \n",
      "batch_normalization_5 (1, 56, 56, 128) \n",
      "conv2d_4 (1, 56, 56, 256) \n",
      "batch_normalization_6 (1, 56, 56, 256) \n",
      "conv2d_5 (1, 56, 56, 256) \n",
      "batch_normalization_7 (1, 56, 56, 256) \n",
      "conv2d_6 (1, 56, 56, 256) \n",
      "batch_normalization_8 (1, 56, 56, 256) \n",
      "max_pooling2d_2 (1, 28, 28, 256) \n",
      "batch_normalization_9 (1, 28, 28, 256) \n",
      "conv2d_7 (1, 28, 28, 512) \n",
      "batch_normalization_10 (1, 28, 28, 512) \n",
      "conv2d_8 (1, 28, 28, 512) \n",
      "batch_normalization_11 (1, 28, 28, 512) \n",
      "conv2d_9 (1, 28, 28, 512) \n",
      "max_pooling2d_3 (1, 14, 14, 512) \n",
      "batch_normalization_12 (1, 14, 14, 512) \n",
      "flatten (1, 100352) \n",
      "batch_normalization_13 (1, 100352) \n",
      "dense (1, 512) \n",
      "batch_normalization_14 (1, 512) \n",
      "dense_1 (1, 2) \n"
     ]
    }
   ],
   "source": [
    "keract.display_activations(a, directory='cat_activations', save=True, fig_size=(100,24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x244d4e94388>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def SRM(imgs):\n",
    "#     c=np.zeros((3,5,5))\n",
    "#     c[0]=[[-1,2,-2,2,-1],[2,-6,8,-6,2],[-2,8,-12,8,-2],[2,-6,8,-6,2],[-1,2,-2,2,-1]]\n",
    "#     c[0]=c[0]/12\n",
    "\n",
    "#     c[1][1][1]=-1\n",
    "#     c[1][1][2]=2\n",
    "#     c[1][1][3]=-1\n",
    "#     c[1][2][1]=2\n",
    "#     c[1][2][2]=-4\n",
    "#     c[1][2][3]=2\n",
    "#     c[1][3][1]=-1\n",
    "#     c[1][3][2]=2\n",
    "#     c[1][3][3]=-1\n",
    "#     c[1]=c[1]/4\n",
    "\n",
    "#     c[2][1][2]=1\n",
    "#     c[2][2][2]=-2\n",
    "#     c[2][3][2]=1\n",
    "#     c[2]=c[2]/2   \n",
    "\n",
    "#     Wcnn=np.zeros((5,5,3,3))\n",
    "#     for i in range(3):\n",
    "#         Wcnn[:,:,0,i]=c[i]\n",
    "#         Wcnn[:,:,1,i]=c[i]\n",
    "#         Wcnn[:,:,2,i]=c[i]\n",
    "\n",
    "#     imgs = np.array(imgs, dtype=float)\n",
    "#     input = tf.Variable(imgs, dtype=tf.float32)\n",
    "\n",
    "#     conv = tf.nn.conv2d(input, Wcnn, [1, 1, 1, 1], padding='SAME',name='srm')\n",
    "#     res = np.array(conv, dtype=float)\n",
    "#     return res"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/tensorflow-2.3-gpu-py37-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "31aaf77f4ef1b20c95cd356702cf001ae279ac9168f3d41b4fe8c593a8672def"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
