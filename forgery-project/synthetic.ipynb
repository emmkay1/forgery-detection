{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/site-packages (3.4.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/site-packages (from matplotlib) (1.18.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/site-packages (from matplotlib) (7.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Input\n",
    "# import tf_slim as slim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import itertools\n",
    "import random\n",
    "%matplotlib inline\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializer():\n",
    "    filter1 = [[0, 0, 0, 0, 0],\n",
    "               [0, -1, 2, -1, 0],\n",
    "               [0, 2, -4, 2, 0],\n",
    "               [0, -1, 2, -1, 0],\n",
    "               [0, 0, 0, 0, 0]]\n",
    "    filter2 = [[-1, 2, -2, 2, -1],\n",
    "               [2, -6, 8, -6, 2],\n",
    "               [-2, 8, -12, 8, -2],\n",
    "               [2, -6, 8, -6, 2],\n",
    "               [-1, 2, -2, 2, -1]]\n",
    "    filter3 = [[0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0],\n",
    "               [0, 1, -2, 1, 0],\n",
    "               [0, 0, 0, 0, 0],\n",
    "               [0, 0, 0, 0, 0]]\n",
    "    q = [4.0, 12.0, 2.0]\n",
    "    filter1 = np.asarray(filter1, dtype=float) / 4\n",
    "    filter2 = np.asarray(filter2, dtype=float) / 12\n",
    "    filter3 = np.asarray(filter3, dtype=float) / 2\n",
    "    filters = [[filter1, filter1, filter1], [filter2, filter2, filter2], [filter3, filter3, filter3]]\n",
    "    filters = np.einsum('klij->ijlk', filters)\n",
    "    filters = tf.Variable(filters, dtype=tf.float32)\n",
    "    return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 224\n",
    "w = 224\n",
    "image_size = (h, w)\n",
    "\n",
    "# np_arr = lambda img: img.resize(image_size).flatten() / 255.0\n",
    "np_arr = lambda img: np.array(img.resize(image_size)).flatten() / 255.0\n",
    "\n",
    "def prepare_image(image_path):\n",
    "    # img = Image.open(image_path)\n",
    "    # img = img.resize(image_size)\n",
    "    # img = np.asarray(img)\n",
    "    # imgs = np.array(img, dtype=float)\n",
    "    # input = tf.Variable(imgs, dtype=tf.float32)\n",
    "    return np_arr(Image.open(image_path))\n",
    "    # SRM([img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # SRM converted images\n",
    "Y = [] # 0 for fake, 1 for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(path, cls):\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('jpg') or filename.endswith('png'):\n",
    "                try:\n",
    "                    full_path = os.path.join(dirname, filename)\n",
    "                    X.append(prepare_image(full_path))\n",
    "                    Y.append(cls)\n",
    "                except:\n",
    "                    pass\n",
    "                if len(Y) % 500 == 0:\n",
    "                    print('Processing {} images'.format(len(Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 500 images\n",
      "Processing 1000 images\n",
      "Processing 1500 images\n",
      "Processing 2000 images\n",
      "Processing 2500 images\n",
      "Processing 3000 images\n",
      "Processing 3500 images\n",
      "Processing 4000 images\n",
      "Processing 4500 images\n",
      "Processing 5000 images\n",
      "Processing 5500 images\n",
      "Processing 6000 images\n",
      "Processing 6500 images\n",
      "Processing 7000 images\n",
      "Processing 7500 images\n",
      "Processing 8000 images\n",
      "8173 8173\n"
     ]
    }
   ],
   "source": [
    "#place authentic\n",
    "Au_path = '../synthetic/Au'\n",
    "prepare_data(Au_path, 1)\n",
    "random.shuffle(X)\n",
    "# X = X[:2100]\n",
    "# Y = Y[:2100]\n",
    "print(len(X), len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 8500 images\n",
      "Processing 9000 images\n",
      "Processing 9500 images\n",
      "Processing 10000 images\n",
      "Processing 10500 images\n",
      "Processing 11000 images\n",
      "Processing 11500 images\n",
      "Processing 12000 images\n",
      "12477 12477\n"
     ]
    }
   ],
   "source": [
    "#place tampered\n",
    "Tp_path = '../synthetic/Tp'\n",
    "prepare_data(Tp_path, 0)\n",
    "print(len(X), len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = to_categorical(Y, 2)\n",
    "X = X.reshape(-1, h, w, 3)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size = 0.2, random_state=5)\n",
    "\n",
    "X = X.reshape(-1,1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer_srm = initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-05-05 02:27:10.262 tensorflow-2-3-gp-ml-g4dn-12xlarge-1be1fa3f01e6a5645cff1d084b39:1047 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2021-05-05 02:27:10.285 tensorflow-2-3-gp-ml-g4dn-12xlarge-1be1fa3f01e6a5645cff1d084b39:1047 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_srm-layer (Tenso [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 220, 220, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 110, 110, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 108, 108, 64)      18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 108, 108, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 106, 106, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 53, 53, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 53, 53, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 51, 51, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 51, 51, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 49, 49, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 73728)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               18874624  \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 19,164,834\n",
      "Trainable params: 19,163,490\n",
      "Non-trainable params: 1,344\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(h, w, 3))\n",
    "op = tf.nn.conv2d(input, initializer_srm, strides=[1, 1, 1, 1], padding='SAME', name='srm-layer')\n",
    "x = Conv2D(32, 3, padding='valid', activation='relu')(op)\n",
    "x = Conv2D(32, 3, padding='valid', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "# x = Dropout(0.25)(x)\n",
    "\n",
    "x = Conv2D(64, 3, padding='valid', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, 3, padding='valid', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "# x = Dropout(0.25)(x)\n",
    "\n",
    "x = Conv2D(128, 3, padding='valid', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(128, 3, padding='valid', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# x = Conv2D(256, 3, padding='valid', activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Conv2D(256, 3, padding='valid', activation='relu')(x)\n",
    "# x = MaxPool2D(pool_size=2)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "\n",
    "# x = Conv2D(512, 3, padding='valid', activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Conv2D(512, 3, padding='valid', activation='relu')(x)\n",
    "# x = MaxPool2D(pool_size=2)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 32\n",
    "init_lr = 1e-4\n",
    "# optimizer = Adam(lr = init_lr)\n",
    "optimizer = Adam(lr = init_lr, decay = init_lr/epochs)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0,patience=10, verbose=0, mode='auto')\n",
    "\n",
    "checkpoint_filepath = 'srm_synthetic_8/checkpoint'\n",
    "model_checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True, monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "312/312 [==============================] - ETA: 0s - loss: 0.4692 - accuracy: 0.8242WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0066s vs `on_test_batch_end` time: 0.0252s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0066s vs `on_test_batch_end` time: 0.0252s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 44s 142ms/step - loss: 0.4692 - accuracy: 0.8242 - val_loss: 1.3642 - val_accuracy: 0.6554\n",
      "Epoch 2/50\n",
      "312/312 [==============================] - 42s 134ms/step - loss: 0.3052 - accuracy: 0.8776 - val_loss: 0.4637 - val_accuracy: 0.8542\n",
      "Epoch 3/50\n",
      "312/312 [==============================] - 38s 121ms/step - loss: 0.2452 - accuracy: 0.9021 - val_loss: 0.4706 - val_accuracy: 0.8305\n",
      "Epoch 4/50\n",
      "312/312 [==============================] - 38s 122ms/step - loss: 0.1989 - accuracy: 0.9271 - val_loss: 0.4965 - val_accuracy: 0.8486\n",
      "Epoch 5/50\n",
      "312/312 [==============================] - 38s 122ms/step - loss: 0.1626 - accuracy: 0.9415 - val_loss: 0.5985 - val_accuracy: 0.8149\n",
      "Epoch 6/50\n",
      "312/312 [==============================] - 38s 123ms/step - loss: 0.1503 - accuracy: 0.9461 - val_loss: 0.5397 - val_accuracy: 0.8201\n",
      "Epoch 7/50\n",
      "312/312 [==============================] - 39s 124ms/step - loss: 0.1384 - accuracy: 0.9515 - val_loss: 0.8005 - val_accuracy: 0.7897\n",
      "Epoch 8/50\n",
      "312/312 [==============================] - 39s 126ms/step - loss: 0.1284 - accuracy: 0.9560 - val_loss: 0.5960 - val_accuracy: 0.8425\n",
      "Epoch 9/50\n",
      "312/312 [==============================] - 39s 124ms/step - loss: 0.1080 - accuracy: 0.9659 - val_loss: 0.5857 - val_accuracy: 0.8369\n",
      "Epoch 10/50\n",
      "312/312 [==============================] - 38s 122ms/step - loss: 0.1052 - accuracy: 0.9631 - val_loss: 0.5757 - val_accuracy: 0.8333\n",
      "Epoch 11/50\n",
      "312/312 [==============================] - 38s 122ms/step - loss: 0.0975 - accuracy: 0.9684 - val_loss: 0.6423 - val_accuracy: 0.8193\n",
      "Epoch 12/50\n",
      "312/312 [==============================] - 38s 121ms/step - loss: 0.0941 - accuracy: 0.9685 - val_loss: 0.6422 - val_accuracy: 0.8321\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val), callbacks=[early_stopping, model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_set = [] # SRM converted images\n",
    "Y_test_set = [] # 0 for fake, 1 for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(path, cls):\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('jpg') or filename.endswith('png'):\n",
    "                try:\n",
    "                    full_path = os.path.join(dirname, filename)\n",
    "                    X_test_set.append(prepare_image(full_path))\n",
    "                    Y_test_set.append(cls)\n",
    "                except:\n",
    "                    pass\n",
    "                if len(Y_test_set) % 500 == 0:\n",
    "                    print('Processing {} images'.format(len(Y_test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 500 images\n",
      "790 790\n"
     ]
    }
   ],
   "source": [
    "#place authentic\n",
    "# synthetic_test/Au\n",
    "Au_path = '../synthetic_test/Au'\n",
    "prepare_data(Au_path, 1)\n",
    "random.shuffle(X_test_set)\n",
    "# X = X[:2100]\n",
    "# Y = Y[:2100]\n",
    "print(len(X_test_set), len(Y_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1000 images\n",
      "1190 1190\n"
     ]
    }
   ],
   "source": [
    "#place tampered\n",
    "Tp_path = '../synthetic_test/Tp'\n",
    "prepare_data(Tp_path, 0)\n",
    "print(len(X_test_set), len(Y_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_set = np.array(X_test_set)\n",
    "Y_test_set = to_categorical(Y_test_set, 2)\n",
    "X_test_set = X_test_set.reshape(-1, h, w, 3)\n",
    "\n",
    "x_test, x_test2, y_test, y_test2 = train_test_split(X_test_set, Y_test_set, test_size = 0.2, random_state=5)\n",
    "\n",
    "# X_test = X_test.reshape(-1,1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "average_precision = average_precision_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8406762487084554"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyhElEQVR4nO3dd3iUZfbw8e9J6EWkBKQ3A4JCKBEULCgWUBcWsAA2ll3bigrqKnZ+eLHqyq7iu8iKq6K4ioqAqKhrAXUlwSQ0pUnASGgxVEMNSc77xz1JhpCQSTLJk8ycz3XNNTNPmzMwOXPPXUVVMcYYE7oivA7AGGNM+bJEb4wxIc4SvTHGhDhL9MYYE+Is0RtjTIir5nUABTVp0kTbtWvndRjGGFOlJCUl7VLVqML2VbpE365dOxITE70OwxhjqhQR+aWofVZ1Y4wxIc4SvTHGhDhL9MYYE+Is0RtjTIizRG+MMSHOEr0xxoQ4S/TGGBPiKl0/emOM8UpODuzYAb/84m5paW6bqrvB8ffB3taqFdx6a/DflyV6Y0zYyMyE1NT8RF7wlpoKx455F98551iiN8ZUAmlpEBcHS5e62969cOqp+beGDY+/L+zxKadAZGTwYztwoOgk/ssvrrTuv9aSCDRvDm3bQp8+cM017nHurXlzqFYt/1iR/MfB3FbeLNEbY4qUnQ1r1uQn9aVLYdMmt69GDejdG844A/bvd18A69fDvn3ulpNz8ms3aFD0F0FR2045BdLTi07ke/Yc/xrVq0Pr1i5pX3bZ8Um8bVu3r0aNYP6LVU6W6I0xefbvh2XL8pN6fDxkZLh9zZpBv35w++3uvlcvqFWr8OuouvNyk/7evcffF/Z406b8xwcOBBZv3br5Sbtv3xMT+Wmnlc8vh6rGEr0xYUoVkpOPr4b58Ue3PSICunWDG25wSb1fP2jfPvCqBhFX+j7lFGjTpuSxZWXlfwn4fyns3w+NG+cn8kaNKq76oyqzRG9MmDh8GBITj6+G2bXL7WvQAM4919VR9+vn6qvr1/cu1mrVoEkTdzNlZ4nemBC1bdvxSX35cldSBujUCa66Kr+03qWLK8Wb0GSJ3pgqKivLNYBu3+6S+vbt7pZbHbNlizuuVi1XQr//fpfUzzkHogpdnsKEKkv0xlQyqrB794kJvODjtLTjuwqCa3hs1col83vvdYk9JiY8epaYogWU6EVkEDANiAT+rapPF9jfFngViAL2ADeo6lbfvmzgB9+hW1R1SJBiN6bKycg4eQLPvWVmnnhukybQogW0bAk9euQ/btEi/3FUlPUyMScqNtGLSCQwHbgU2AokiMhCVV3rd9hU4A1VfV1ELgaeAm707Tusqj2CG7YxlU9WlkvaKSnu9ssv+ffbtrlbYd0G69fPT9bnnXd84s593Lw51KxZwW/IhIxASvR9gGRV3QwgInOAoYB/ou8K3Ot7vBhYEMQYjakU/IfP+yfy3Mdbt7oBRv5yR1127w6DBp2YwFu08LZ3iwkPgST6lkCq3/OtQN8Cx6wChuOqd4YB9UWksaruBmqJSCKQBTytqgsKvoCI3ArcCtCmNJ1ujQmCI0dcA2ZRiXzbthOHz7dq5RL5+ee7+3bt8u9bty56QJExFSlYjbH3A/8UkTHAN8A2ILds01ZVt4lIB+ArEflBVTf5n6yqM4GZALGxsQWal4wpO1XXZzy3Ttw/oecm8h07jj8nMjJ/+PzAgccn8bZtXZK3Rk5TFQSS6LcBrf2et/Jty6Oq23ElekSkHjBCVff59m3z3W8WkSVAT+C4RG9MWRw5kp/Ai7oV1sBZvbobtdmuHQwefHwib9fOVatUs35pJgQE8jFOAKJFpD0uwY8ERvsfICJNgD2qmgM8hOuBg4g0BA6p6lHfMf2BvwUxfhPCckvhRSXu3Me7d594bp06ri68ZUvo3z//ce6tVStXf249VEw4KDbRq2qWiIwDPsN1r3xVVdeIyGQgUVUXAgOAp0REcVU3d/pO7wK8JCI5uNWsni7QW8eEOVVYuRIWL3aNmcWVwkXc5FotW7pSd2FJvEULN6Tf5kAxxhEtOOLCY7GxsZqYmOh1GKYcqUJSErz3HsydC5s3u+11656YtHMTd+7j005zVS7GmOOJSJKqxha2z2ogTYVQddPfzp3rbr/84uq/Bw6Ehx928640bWqlcGPKgyV6U25yctycK3Pnwvvvuz7o1au7BSAmTYIhQ9w0s8aY8mWJ3gRVdjZ8911+ct++3XVBHDQIpkyB3/3OrRRkjKk4luhNmWVlwbffuuQ+bx7s3OkGCg0eDFdf7aplTjnF6yiNCV+W6E2pZGXBkiWuQXX+fLeOZ+3acOWVLrlfeSXUq+d1lMYYsERvSuDYMfjqK5fcFyxw/dfr1nUl9quvdiX4unW9jtIYU5AlenNSR4/CF1+4apkPPnBrd9av7+rar7kGLr/cleSNMZWXJXpzAlX49FN4+21YuNAtyNyggeslc801cOmlNlmXMVWJJXpznMREmDAB/vc/aNgQhg931TIDB9p86MZUVZboDeCmHHj4YXjjDTdwaeZMuPlmm53RmFBgiT7MHToEf/87PP2060nz4IMu4Vt3SGNChyX6MKUKc+a4xJ6a6qpnnnkGOnTwOjJjTLBFeB2AqXjx8dCvH4we7Rac/vpr12XSkrwxockSfRhJTYXrr4dzz3WrKr32mmt8veACryMzxpQnq7oJAwcPwt/+Bs8+6yYae+QRmDjRRq4aEy4s0YewnBx480146CE3udh117l6+LZtvY7MGFORrOomRH33HfTt67pItmzp+sXPmWNJ3phwZIk+xKSkuJL7eefBjh0we7ZrfO3f3+vIjDFesaqbEJGR4frC//3vEBEBTzwBf/mLTTJmjLFEX+VlZ8Prr7sG1p07Xa+ap56C1q29jswYU1lYoq/Cvv7azUuzYgWcc46bOrhvX6+jMsZUNlZHXwVt3gwjRsCAAbBrF7z1FixdakneGFO4gBK9iAwSkQ0ikiwiEwvZ31ZEvhSR1SKyRERa+e27WUQ2+m43BzP4cPPbb27Kgi5d3DTCTz4J69fDqFEg4nV0xpjKqthELyKRwHRgMNAVGCUiXQscNhV4Q1W7A5OBp3znNgKeAPoCfYAnRKRh8MIPD1lZbjbJ6Gg38GnUKNi4ER59FOrU8To6Y0xlF0iJvg+QrKqbVTUTmAMMLXBMV+Ar3+PFfvsvBz5X1T2quhf4HBhU9rDDx2efQY8ecNtt0KkTJCTArFnQooXXkRljqopAEn1LINXv+VbfNn+rgOG+x8OA+iLSOMBzTSF+/BEGDXK3I0fcUn7ffAOxsV5HZoypaoLVGHs/cKGIrAAuBLYB2YGeLCK3ikiiiCSmp6cHKaSqKS3Nld5jYmDZMtcvfs0a1/hq9fDGmNIIJNFvA/x7ZbfybcujqttVdbiq9gQe8W3bF8i5vmNnqmqsqsZGRUWV7B2EiMOH4a9/hdNPh1dfhbvuguRkuPdeW8LPGFM2gST6BCBaRNqLSA1gJLDQ/wARaSIiudd6CHjV9/gz4DIRaehrhL3Mt8345E481rmzG/R0ySWuBP/889C4sdfRGWNCQbGJXlWzgHG4BL0OeFdV14jIZBEZ4jtsALBBRH4CmgFTfOfuAZ7EfVkkAJN92wzw7beu7/uNN0JUFCxZAvPnu0ZXY4wJFlFVr2M4TmxsrCYmJnodRrlKTnb94efNczNLPvWUm7ogwoavGWNKSUSSVLXQ7hqWWirQnj1uyoKuXV23ySefhJ9+ciV6S/LGmPJic91UgMxMePFFmDwZ9u+HsWPd4+bNvY7MGBMOrBxZjlTdRGNnnulK8rGxbgKyl1+2JG+MqTiW6MtJUpKbdGzYMKheHRYtctU13bt7HZkxJtxYog+y1FS46SZXel+3DmbMgNWrYfBgG/BkjPGG1dEHSUaGm3Bs6lRXZTNxoluU+5RTvI7MGBPuLNGXUXa2G8n62GNu+oJRo1x3SVuE2xhTWViiL4P//hfuvx9++MEtvv3BB7b4hzGm8rE6+lKaMgUuvxwOHoT33ssf5WqMMZWNlehLYf58t+jH6NGu2sYmHTPGVGZWoi+h1avdSNY+feCVVyzJG2MqP0v0JZCeDkOGQIMGrlRfq5bXERljTPGs6iZAmZlw9dWwc6erj7el/IwxVYUl+gDdc49byu/NN+Hss72OxhhjAmdVNwGYMQP+9S83tfD113sdjTHGlIwl+mIsXgx33w1XXum6VBpjTFVjif4kNm929fLR0fDWWxAZ6XVExhhTcpboi5CR4XrYqMLChTZnjTGm6rLG2ELk5MANN8D69W5q4dNP9zoiY4wpPUv0hXj8cVeKf+EFGDjQ62iMMaZsrOqmgHfecY2uf/oTjBvndTTGGFN2luj9JCXBH/4A550H06fbQiHGmNBgid5n5074/e+hSRN4/32oUaOYE44dcwvAqlZEeMYYU2oBJXoRGSQiG0QkWUQmFrK/jYgsFpEVIrJaRK7wbW8nIodFZKXv9q9gv4FgOHoUhg+HPXtc3XzTpgGcNHMm9OrlJqL/3//KPUZjjCmtYhO9iEQC04HBQFdglIh0LXDYo8C7qtoTGAm86Ldvk6r28N1uD1LcQaMKt98OcXEwaxb06BHgiV9/DQ0bQkoKnH++64u5Zk35BWqMMaUUSIm+D5CsqptVNROYAwwtcIwCuT3NGwDbgxdi+Zo2zSX4xx+Ha64pwYnx8W7lkeRk+OtfXeLv3h3GjnUrhBtjTCURSKJvCfhnrq2+bf4mATeIyFZgEXCX3772viqdr0Xk/MJeQERuFZFEEUlMT08PPPoy+u9/4b77YNgweOKJEpy4bZtL5uecA3XquFXAN2+G8ePhP/+BTp3cxDh795ZX6OUnMxPefddN6jN/vtfRGGOCIFiNsaOAWaraCrgCmC0iEcAOoI2vSude4C0ROWGMqarOVNVYVY2NiooKUkgn99NPcN11cNZZ8MYbEFGSf4n4eHd/7rn52xo3hr//3V342mvh2WehQwd3f/hwUGMvF1u2uGWz2rRx/zDz57uGi/vucw3PxpgqK5D0tg1o7fe8lW+bvz8C7wKoahxQC2iiqkdVdbdvexKwCehU1qDLav9+V6VerZpb0LtevRJeIC7OLS1VWIV+27bw+uuwciX06wcPPOBK+K+9BtnZQYg+iHJy4NNPYehQaN/eVUGdfTYsWuRapseNg3/8Ay66yP2KMcZUSYEk+gQgWkTai0gNXGPrwgLHbAEGAohIF1yiTxeRKF9jLiLSAYgGNgcr+NLIzoaRI2HTJteNsl27UlwkPh569z55H8zu3eHjj930ly1auLr7mBj48EPvu2Tu2uV+aXTqBIMHu/fz4IOu+unDD922WrXg//0/ePtt96XVqxd89ZW3cRtjSkdVi73hqmN+wpXIH/FtmwwM8T3uCnwHrAJWApf5to8A1vi2LQd+V9xr9e7dW8vT/fergupLL5XyAkePqtasqXrvvYGfk5Oj+t57qtHR7sXPO0/1u+9KGUAp5eSoLl2qeuONLn5QveAC1bffdu/pZNauVe3SRTUiQnXKFNXs7IqJ2ZTc7NmqLVqoduum+rvfqd59t+pzz6kuWKC6cqXq/v1eR2jKCZCoReXwonZ4dSvPRP/66+4d33lnGS7y/ffuIu+9V/JzMzNVZ8xQbdbMXeP3v1ddt64MwQQgI8N9q/Xo4V6zfn33D/DDDyW/zujR7hpXXqm6e3f5xGtK75tvVKtXV+3VS3XIEJfs69Vz/2f+t0aNVHv3Vh0xwpV8pk9XXbTIfRYPHfL6XZhSOlmiF/W6GqGA2NhYTUxMDPp14+Phwgvd+KbPPoPq1Ut5oRdecOsKpqZCq1alu8aBA/D88/C3v8HBg/DHP7puPy0LdmYqg7Vr3dJYb7wBv/3mqo3uuMP1pilxo4SPqltqa/x4aN4c5s6F2NjgxWxKLyXFta80auQ+7A0buu2qsHu32//zz/m33OcpKW7EoL/TTnNtNu3bu7rN3Mft20Pr1mX44zHlSUSSVLXQP8iwSPTbtrl8VLs2JCS4DjKlNnq0Wx08GH3l09PdDGovvuhahsePd423p55auutlZrreMi++6Ba4rVHD9QD6859dV9BgTd6TkJC/Uvq0aXDbbTYxkJcyMlwJJjUVli1zbS+Byslx/4/+yd//y2DLluM7EUREuAKO/xdBq1YQFeWGlEdFuVv9+vaZqGBhnegPH4YLLnBzy8fFue6UZdKhg2uIfe+9oMQHuD+qxx5zffAbNYJHHnHJuVatwM7/5Rc3JcMrr0Bamovx9tvdDG1NmgQvTn+7d8ONN8Inn7hfCS+9BHXrls9rmaLl5LiBIB9/7P4vLr00uNfPyoKtWwv/Ivj5Z9hexNjIGjXyk34gt1NPLWEfZ1NQ2CZ6VbeAyNtvw4IFrktlmaSluZ+1U6e6/uXBtmKFG3z12WeuP/uTT7okWtgahjk57rgZM9wfOcBVV7nqmcsuq5g/mpwc1yXz8ceha1fXjalz5/J/XZPv4YfhqadcDykv5tU+csT9IkhPD+yWkVH4dSIjXaGksC8B/18KTZu6Xyy2rucJTpboPW98LXgLZmPs00+7tqcpU4J0wQUL3AXLu8fMF1+4xjJwDWoff+x6zaiqpqerPvOMaocObn+zZqqPPKL6yy/lG9PJfP65alSUa/h75x3v4gg3b77pPgO33Zb/+ajsDh9WTU1VXb5c9bPP3Ht47jnVhx5S/dOfVIcOVe3Xz/VQO/XUExuSwX3WbrlF9ZNPiu8xVlUcPer+7hcsKPUlCMdeNx9+qCqiOnJkEP8GHnzQ9Wo4fDhIFzyJ7GzVOXNUO3Z0/00DBqhef71qjRru+YUXuv2V5YOemur+QMF16asscYWq+HjXTXbAANebK1RlZqpu3666apVLhLNmuT/q3N5Ep5zi/i7ef1/1wAGvoy2Z7dtVX3lFdfhw1xsOVM86q9SXC7tEv2aN+3fr3Vv14MEyXy7fhReq9ukTxAsG4OhR1X/+U7VpU/ehHjdO9ccfKzaGQGVmqk6Y4D5W55yjumWL1xGFpi1b3C+5Dh1Ud+3yOhpvHD6s+tFHqmPHqjZu7D5ztWu7LstvvKG6Z4/XEZ4oO9t9QT/2mOsCm/sLpVUr96ts4cIyfVmdLNGHXB39nj3Qp4/rwZiYWPoekCfIyoIGDdwag9OmBemiJXDsmKsTr1mz4l+7pObOdSOBa9SAt95ybQYmOA4edNNiJye73gVnnul1RN7LynI94ebPh3nzXDe7atXg4ovdfE1Dh7q2NS/s2+dmT8xtLE9Pd+1n554LV17pbt26BaWHUtjU0R87pjpwoKvdWLq01Jcp3PLl7tv37beDfOEQtWGD+xkqojppko2mDYbsbNWrr3b/ph9/7HU0lVN2tuqyZa6a9fTT3d+siBuN/o9/qP78c/m+fk6O+8X9zDNu5HlkpOYNUrv+etW33iq3X2GES9XN3Xe7dzRrVqkvUbTp093Fy/uDEkoOHlS96Sb373b55a4h2ZTepEnu33LqVK8jqRpyctwI8P/7P9WYmPyqkp49VZ980tXxBqMB79Ah98X75z+rtm2b/zoxMaoPP+w6b2Rllf11ihEWiX7dOtVq1Uo2BU2J3Hij6mmnVZ3eDZVFTo7qzJmu4bB1a1dHaUru3Xfdn+uYMfYZLK3kZNVnn1U999z8ZNy5s+vxk5BQsn/XlBRX+LviCtVatdy16tRxU0+89JLrnFDBTpboQ6qOfvlyN2lktWpBDgogOtqNtrLFOEonKcmNpt22zc3bP26cjZwMVFKSq5fv2dPNIFoV2mkqu+3b3Rzl8+a5GWazs930DsOHuwFo5513fF/9rCxYutTVtX/8cf6yoR075te1X3BB4IMcy0HYDpgKml273GCNZ55xUxSY0tm7F266CT76yC1u8vLLbqh8eTlyxA3h37LFjR7OfbxlC3Tp4gZ7nXLCOjiVy44dbg6byEj4/nto1szriELP7t3uMzlvnhuEePSo+3sfOtSNgl+82G3fv9+VIi+4ID+5d+pUaQoslujL6qOP4He/c+vCXnCB19FUbTk5bjK3Rx5xfyRz55au54j6JuvyT+C5j3Pvf/31+HNE3NoALVu6LlmtW7tJ3yrr/+nhwzBggCs9fvedm5jOlK8DB1zvmHnz3N/9gQPuy/WKK1xiv/TSSls4OFmiL49KjtATH+9KVDZTY9lFRMDEidC3r1sBpk8fV7IfPfr44zIzXTVPYQk893bo0PHn1K7tVvhq08ZVc7Rpk/+8TRvX1zZ35sW4ODdXz4AB8Je/wOTJlatKRBVuucWV4ufPtyRfUerVg2uucbcjR9xnLjq6ys/DYyX6QFxyiat2SEryOpLQsn27S/bffgsjRrgknJvMt28/cSWupk2PT9y5j3PvGzcu2c/oAwfcnEUzZ7rGnTffdH2aK4Onn3bzHk2Z4uazMaYYVnVTFtnZbma9m26C6dO9jib0ZGW5RPavf7lEXrAUnvu4dWtXYi8PH33kBsLt3esS64QJ3k6a9cEHrkFw5Eg3o2klqQM2lZsl+rL44QdX2ps9202FaUJTerqbV3/+fLdCzeuvuy+ZirZ6tVtUvmtX1yZUXl9uJuScLNFX7YqnihAX5+7POcfbOEz5iopy0yy/9prrp9utm2uorciC0K+/urm0GzRw82pbkjdBYom+OPHxbp7sjh29jsSUNxEYM8aVqnv0gJtvdn3/d+0q/9c+etS1U6SluaqbFi3K/zVN2LBEX5y4uOAuw2cqv3btXN/pv/0NPvzQDZRbtKj8Xk/VLRjzv//BrFnWu8sEnSX6k9m7161BeO65XkdiKlpkpOt2mZDgGomvvNIl44MHg/9azz/vqowef9wNJDMmyAJK9CIySEQ2iEiyiEwsZH8bEVksIitEZLWIXOG37yHfeRtE5PJgBl/uli1z91Y/H75iYlxf9vvvd+vi9uiR/7kIhk8+cdceMQKeeCJ41zXGT7GJXkQigenAYKArMEpEuhY47FHgXVXtCYwEXvSd29X3/ExgEPCi73pVQ3y8Gyhx9tleR2K8VKsWPPusq87JzIT+/V3p+9ixsl133TrXhbJ7d9fLp4oPyjGVVyCfrD5AsqpuVtVMYA4wtMAxCuSOC24A5C4NPxSYo6pHVfVnINl3vaohLs7Vz5bnfCym6rjwQtdQe8MNbuH2c891VXulsXu3m1ajdm3X+Fq3bnBjNcZPIIm+JZDq93yrb5u/ScANIrIVWATcVYJzK6ecHPcT3ernjb8GDVyD6dy5kJLiplr45z/d5yVQx465Ifapqa7ffps25RWtMUDwGmNHAbNUtRVwBTBbRAK+tojcKiKJIpKYnp4epJDKaP16N1ud1c+bwowY4QbTXXwx3HUXDB7s5uYJxD33uGqgf//bChKmQgSSjLcBrf2et/Jt8/dH4F0AVY0DagFNAjwXVZ2pqrGqGhsVFRV49OUpPt7dW6I3RWne3E2f8K9/ua6R3brBO++c/JwXX4QZM+DBB92kasZUgEASfQIQLSLtRaQGrnF1YYFjtgADAUSkCy7Rp/uOGykiNUWkPRANfB+s4MtVfDw0bOim0jWmKCJu6oSVK91nZeRIuP561zW3oC++gLvvdnXzU6ZUeKgmfBWb6FU1CxgHfAasw/WuWSMik0VkiO+w+4BbRGQV8DYwxre61RpcSX8t8Clwp6pml8cbCbq4ODeVrvWEMIGIjnal+smTXam+e3f48sv8/Rs3unr5Ll3cRGVeTppmwo5NalaY335zM1ZOmuS60RlTEomJrmfOhg2uPn7iRDfv/a5dbgBW+/ZeR2hCkE1qVlLff++GpVv9vCmN2Fg3Mdpdd8G0aW5KhU2b3KpFluSNByzRFyY+3tW99u3rdSSmqqpTB154wa012qmT62FTWZcsNCHPlhIsTFycq0tt0MDrSExVd9llbpCVMR6yEn1Bqq5Eb/2bjTEhwhJ9QRs3wp49Vj9vjAkZlugLyh0oZSV6Y0yIsERfUFwcnHKKq6M3xpgQYIm+oPh4GyhljAkpls38HTjgekhY/bwxJoRYoveXmOimm7VEb4wJIZbo/eU2xNpAKWNMCLFE7y8uzo1ibNzY60iMMSZoLNHnsoFSxpgQZYk+188/w6+/Wv28MSbkWKLPZQOljDEhyhJ9rrg4qFsXzjzT60iMMSaoLNHnio+HPn2gmk3oaYwJLZboAQ4fdmt+Wv28MSYEWaIHSEqCrCyrnzfGhCRL9ODq58EGShljQpIlenD18x07QtOmXkdijDFBZ4le1ZXorX7eGBOiLNGnpsKOHZbojTEhK6BELyKDRGSDiCSLyMRC9j8nIit9t59EZJ/fvmy/fQuDGHtw2EApY0yIK7bTuIhEAtOBS4GtQIKILFTVtbnHqOoEv+PvAnr6XeKwqvYIWsTBFhcHtWtD9+5eR2KMMeUikBJ9HyBZVTeraiYwBxh6kuNHAW8HI7gKER8PsbFQvbrXkRhjTLkIJNG3BFL9nm/1bTuBiLQF2gNf+W2uJSKJIhIvIr8v4rxbfcckpqenBxZ5MBw9CsuXW/28MSakBbsxdiQwV1Wz/ba1VdVYYDTwvIh0LHiSqs5U1VhVjY2KigpySCexYgVkZlr9vDEmpAWS6LcBrf2et/JtK8xIClTbqOo23/1mYAnH1997K3eglJXojTEhLJBEnwBEi0h7EamBS+Yn9J4RkTOAhkCc37aGIlLT97gJ0B9YW/Bcz8THQ9u20Ly515EYY0y5KbbXjapmicg44DMgEnhVVdeIyGQgUVVzk/5IYI6qqt/pXYCXRCQH96XytH9vHc/FxUG/fl5HYYwx5SqgOXlVdRGwqMC2xws8n1TIeUuBbmWIr/xs2+YGS1n9vDEmxIXvyNjcgVJWP2+MCXHhnehr1IAePbyOxBhjylV4J/revaFmTa8jMcaYchWeiT4zExITrdrGGBMWwjPRr14NR45YQ6wxJiyEZ6K3gVLGmDASnok+Ph5atoTWrYs/1hhjqrjwTPS2opQxJoyEX6JPS4Off7b6eWNM2Ai/RG8DpYwxYSY8E3316tCrl9eRGGNMhQi/RB8X50bD1q7tdSTGGFMhwivRZ2VBQoLVzxtjwkp4JfoffoBDh6x+3hgTVsIr0VtDrDEmDIVfom/WDNq18zoSY4ypMOGV6HMHSol4HYkxxlSY8En0u3fDxo3WEGuMCTvhk+itft4YE6bCK9FHRkJsrNeRGGNMhQqfRB8XB927Q926XkdijDEVKjwSfXY2fP+91c8bY8JSeCT6tWshI8Pq540xYSmgRC8ig0Rkg4gki8jEQvY/JyIrfbefRGSf376bRWSj73ZzEGMPXG5DrJXojTFhqFpxB4hIJDAduBTYCiSIyEJVXZt7jKpO8Dv+LqCn73Ej4AkgFlAgyXfu3qC+i+LExUGTJtCxY4W+rDHGVAaBlOj7AMmqullVM4E5wNCTHD8KeNv3+HLgc1Xd40vunwODyhJwqcTH20ApY0zYKrZED7QEUv2ebwX6FnagiLQF2gNfneTcloWcdytwK0CbNm0CCKkE9u6Fdevg+uuDe11jKkBmZiabNm3i0KFDXodiKok6derQsWNHatSoEfA5gST6khgJzFXV7JKcpKozgZkAsbGxGtSIvv/e3VtDrKmCNm3axKmnnkrnzp2JiAiPvhOmaDk5OezcuZPVq1fTqFEjOnToENB5gXxytgGt/Z638m0rzEjyq21Kem75iI93VTZ9+lToyxoTDIcOHaJZs2aW5A0AERERnHbaaQB88MEHbNq0KbDzAjgmAYgWkfYiUgOXzBcWPEhEzgAaAnF+mz8DLhORhiLSELjMt63ixMXBWWdB/foV+rLGBIsleeMvIiICEaF27dqsW7cusHOKO0BVs4BxuAS9DnhXVdeIyGQRGeJ36Ehgjqqq37l7gCdxXxYJwGTftoqRkwPLllm3SmNMyImIiCAzMzOgYwOqo1fVRcCiAtseL/B8UhHnvgq8GlA0wbZhA+zbZ/XzxpTS7t27GThwIAA7d+4kMjKSqKgoAL7//vuTNggmJibyxhtv8MILL5z0Nfr168fSpUuDF7Q5QbAbYysXGyhlTJk0btyYlStXAjBp0iTq1avH/fffn7c/KyuLatUKTyOxsbHEBjCJYFVM8tnZ2URGRnodRsBCO9HHxcGpp0KnTl5HYkyZjR8PvpwbND16wPPPl+ycMWPGUKtWLVasWEH//v0ZOXIk99xzD0eOHKF27dq89tprdO7cmSVLljB16lQ++ugjJk2axJYtW9i8eTNbtmxh/Pjx3H333QDUq1ePAwcOsGTJEiZNmkSTJk348ccf6d27N2+++SYiwqJFi7j33nupW7cu/fv3Z/PmzXz00UfHxZWSksKNN97IwYMHAfjnP/9Jv379AHjmmWd48803iYiIYPDgwTz99NMkJydz++23k56eTmRkJO+99x6pqal5MQOMGzeO2NhYxowZQ7t27bjuuuv4/PPPeeCBB8jIyGDmzJlkZmZy+umnM3v2bOrUqUNaWhq33347mzdvBmDGjBl8+umnNGrUiPHjxwPwyCOP0LRpU+65557S/ceVUGgn+tyBUtaYZUxQbd26laVLlxIZGclvv/3Gt99+S7Vq1fjiiy94+OGHef/99084Z/369SxevJiMjAw6d+7MHXfcQfXq1Y87ZsWKFaxZs4YWLVrQv39/vvvuO2JjY7ntttv45ptvaN++PaNGjSo0pqZNm/L5559Tq1YtNm7cyKhRo0hMTOSTTz7hgw8+YNmyZdSpU4c9e1wz4fXXX8/EiRMZNmwYR44cIScnh9TU1EKvnatx48YsX74ccNVat9xyCwCPPvoor7zyCnfddRd33303F154IfPnzyc7O5sDBw7QokULhg8fzvjx48nJyWHOnDl8n9v1uwKEbqL/7Tf48UcYMcLrSIwJipKWvMvTNddck1d1sX//fm6++WY2btyIiHDs2LFCz7nyyiupWbMmNWvWpGnTpqSlpdGqVavjjunTp0/eth49epCSkkK9evXo0KED7du3B2DUqFHMnDnzhOsfO3aMcePGsXLlSiIjI/npp58A+OKLL/jDH/5AnTp1AGjUqBEZGRls27aNYcOGAVCrVq2A3vd1112X9/jHH3/k0UcfZd++fRw4cIDLL78cgK+++oo33ngDgMjISBo0aECDBg1o3LgxK1asIC0tjZ49e9K4ceOAXjMYQjfRJySAqtXPG1MO6vqt6/DYY49x0UUXMX/+fFJSUhgwYECh59SsWTPvcWRkJFlZWaU6pijPPfcczZo1Y9WqVeTk5AScvP1Vq1aNnJycvOdHjhw5br//+x4zZgwLFiwgJiaGWbNmsWTJkpNe+09/+hOzZs1i586djB07tsSxlUXo1mnE+brz20ApY8rV/v37adnSzWwya9asoF+/c+fObN68mZSUFADeeeedIuNo3rw5ERERzJ49m+xsN0D/0ksv5bXXXsubRmLPnj3Ur1+fVq1asWDBAgCOHj3KoUOHaNu2LWvXruXo0aPs27ePL7/8ssi4MjIyaN68OceOHeM///lP3vaBAwcyY8YMwDXa7t+/H4Bhw4bx6aefkpCQkFf6ryihm+jj46FLF9cYa4wpNw888AAPPfQQPXv2LFEJPFC1a9fmxRdfZNCgQfTu3Zv69evToEGDE47785//zOuvv05MTAzr16/PK30PGjSIIUOGEBsbS48ePZg6dSoAs2fP5oUXXqB79+7069ePnTt30rp1a6699lrOOussrr32Wnr27FlkXE8++SR9+/alf//+nHHGGXnbp02bxuLFi+nWrRu9e/dm7Vo30W+NGjW46KKLuPbaayu8x474jW+qFGJjYzUxMbFsF1GFqCgYOhReeSU4gRnjgaSkJHr37u11GJ47cOAA9erVQ1W58847iY6OZsKECcWfWInk5OTQq1cv3nvvPaKjo8t0raSkJJKSkmjSpAnDhw8HQESSVLXQ/qyhWaJPTobdu22glDEh4uWXX6ZHjx6ceeaZ7N+/n9tuu83rkEpk7dq1nH766QwcOLDMSb40QrMx1gZKGRNSJkyYUOVK8P66du2a16/eC6FZoo+Lc5OYdenidSTGGOO50Ez08fHQty9UoSHKxhhTXkIv0R88CKtXW/28Mcb4hF6iT0yE7GyrnzfGGJ/QS/S5A6X6FrqsrTGmBC666CI+++z4tYKef/557rjjjiLPGTBgALldpK+44gr27dt3wjGTJk3K689elAULFuT1QQd4/PHH+eKLL0oQvckVeok+Pt7NVlmB80gYE6pGjRrFnDlzjts2Z86cIicWK2jRokWcWspBiwUT/eTJk7nkkktKdS2v5I7O9VpoJXpVV6K3+nkTisaPhwEDgnvzTZtblKuvvpqPP/44byWjlJQUtm/fzvnnn88dd9xBbGwsZ555Jk888USh57dr145du3YBMGXKFDp16sR5553Hhg0b8o55+eWXOfvss4mJiWHEiBEcOnSIpUuXsnDhQv7yl7/Qo0cPNm3axJgxY5g7dy4AX375JT179qRbt26MHTuWo0eP5r3eE088Qa9evejWrRvr168/IaaUlBTOP/98evXqRa9evY6bD/+ZZ56hW7duxMTEMHHiRACSk5O55JJLiImJoVevXmzatIklS5Zw1VVX5Z03bty4vOkf2rVrx4MPPpg3OKqw9weQlpbGsGHDiImJISYmhqVLl/L444/zvN/sdY888gjTpk076f9RIEIr0aekwK+/Wv28MUHSqFEj+vTpwyeffAK40vy1116LiDBlyhQSExNZvXo1X3/9NatXry7yOklJScyZM4eVK1eyaNEiEhIS8vYNHz6chIQEVq1aRZcuXXjllVfo168fQ4YM4dlnn2XlypV07Ngx7/gjR44wZswY3nnnHX744QeysrLy5pYBaNKkCcuXL+eOO+4otHoodzrj5cuX88477+TNi+8/nfGqVat44IEHADed8Z133smqVatYunQpzZs3L/bfLXc645EjRxb6/oC86YxXrVrF8uXLOfPMMxk7dmzezJe50xnfcMMNxb5ecUJrwFRu/byV6E0o8mie4tzqm6FDhzJnzpy8RPXuu+8yc+ZMsrKy2LFjB2vXrqV79+6FXuPbb79l2LBheVMFDxmSv9x0UdP9FmXDhg20b9+eTr4FhW6++WamT5+et6hH7pQAvXv3Zt68eSecH47TGYdWoo+Ph7p14ayzvI7EmJAxdOhQJkyYwPLlyzl06BC9e/fm559/ZurUqSQkJNCwYUPGjBlzwpS+gSrpdL/FyZ3quKhpjsNxOuPQqrqJj4ezz4Yi1rA0xpRcvXr1uOiiixg7dmxeI+xvv/1G3bp1adCgAWlpaXlVO0W54IILWLBgAYcPHyYjI4MPP/wwb19R0/3Wr1+fjIyME67VuXNnUlJSSE5OBtwslBdeeGHA7yccpzMOnUR/+DCsWGHVNsaUg1GjRrFq1aq8RB8TE0PPnj0544wzGD16NP379z/p+b169eK6664jJiaGwYMHc/bZZ+ftK2q635EjR/Lss8/Ss2dPNm3alLe9Vq1avPbaa1xzzTV069aNiIgIbr/99oDfSzhOZxzQNMUiMgiYBkQC/1bVpws55lpgEqDAKlUd7dueDfzgO2yLqg4peK6/Uk9TvHMn3Hcf/PGPcPHFJT/fmErIpikOP4FMZ1zSaYqLreMQkUhgOnApsBVIEJGFqrrW75ho4CGgv6ruFZGmfpc4rKo9AnuLZXDaaeD3s8gYY6qatWvXctVVVzFs2LCgTmccSGV2HyBZVTcDiMgcYCiw1u+YW4DpqroXQFV/DVqExhgTJsprOuNA6uhbAql+z7f6tvnrBHQSke9EJN5X1ZOrlogk+rb/vrAXEJFbfcckpqenlyR+Y0Kef+8OY0rzeQhWY2w1IBoYAIwCXhaRU3372vrqjUYDz4tIx4Inq+pMVY1V1dioqKgghWRM1VenTh3S0tIs2RvAJfmdO3dy7NixEp0XSNXNNqC13/NWvm3+tgLLVPUY8LOI/IRL/Amqug1AVTeLyBKgJ7AJY0yxOnbsSHJyMtu2bUNEvA7HVALHjh1jy5YtHD58OOB5hAJJ9AlAtIi0xyX4kbjSub8FuJL8ayLSBFeVs1lEGgKHVPWob3t/4G8BRWaMoUaNGnTt2pWNGzcW21fdhJeGDRvSp0+fgI4tNtGrapaIjAM+w3WvfFVV14jIZCBRVRf69l0mImuBbOAvqrpbRPoBL4lIDq6a6Gn/3jrGmMBER0fTrFkzMjIyCKRLtAlt1apVo2HDhnmjgIsTUD/6ilTqfvTGGBPGTtaPPnRGxhpjjClUpSvRi0g68EsZLtEE2BWkcCobe29VVyi/P3tvlUNbVS2022KlS/RlJSKJRf18qersvVVdofz+7L1VflZ1Y4wxIc4SvTHGhLhQTPQzvQ6gHNl7q7pC+f3Ze6vkQq6O3hhjzPFCsURvjDHGjyV6Y4wJcSGT6EVkkIhsEJFkEZnodTzBJCKtRWSxiKwVkTUico/XMQWbiESKyAoR+cjrWIJJRE4Vkbkisl5E1onIuV7HFEwiMsH3mfxRRN4WkZKvtF1JiMirIvKriPzot62RiHwuIht99w29jLG0QiLR+62CNRjoCowSka7eRhVUWcB9qtoVOAe4M8TeH8A9wDqvgygH04BPVfUMIIYQeo8i0hK4G4hV1bNwc2GN9DaqMpkFDCqwbSLwpapGA1/6nlc5IZHo8VsFS1UzgdxVsEKCqu5Q1eW+xxm4ZFFw8ZcqS0RaAVcC//Y6lmASkQbABcArAKqaqar7PA0q+KoBtUWkGlAH2O5xPKWmqt8AewpsHgq87nv8OvD7iowpWEIl0QeyClZIEJF2uDn9l3kcSjA9DzwAhNrqGu2BdNz03StE5N8iUtfroILFt9bEVGALsAPYr6r/9TaqoGumqjt8j3cCzbwMprRCJdGHBRGpB7wPjFfV37yOJxhE5CrgV1VN8jqWclAN6AXMUNWewEGq6E//wvjqq4fivtBaAHVF5AZvoyo/6vqiV8n+6KGS6ANZBatKE5HquCT/H1Wd53U8QdQfGCIiKbgqt4tF5E1vQwqarcBWVc399TUXl/hDxSXAz6qa7ltdbh7Qz+OYgi1NRJoD+O5/9TieUgmVRJ+3CpaI1MA1CC30OKagEbeG3CvAOlX9h9fxBJOqPqSqrVS1He7/7StVDYlSoaruBFJFpLNv00AglBbe2QKcIyJ1fJ/RgYRQY7PPQuBm3+ObgQ88jKXUAllKsNIrahUsj8MKpv7AjcAPIrLSt+1hVV3kXUgmQHcB//EVQDYDf/A4nqBR1WUiMhdYjusZtoIqPGWAiLwNDACaiMhW4AngaeBdEfkjbvr0a72LsPRsCgRjjAlxoVJ1Y4wxpgiW6I0xJsRZojfGmBBnid4YY0KcJXpjjAlxluiNMSbEWaI3xpgQ9/8BHo9T/S5NDnkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(\"srm.png\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_1 = model.load_weights('srm_synthetic_7/checkpoint.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = model_1.predict(x_test)\n",
    "# average_precision = average_precision_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.12xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/tensorflow-2.3-gpu-py37-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
