{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Input\n",
    "# import tf_slim as slim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import os\n",
    "import itertools\n",
    "import random\n",
    "%matplotlib inline\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ela_image(path, quality):\n",
    "    temp_filename = 'temp_file_name.jpg'\n",
    "    ela_filename = 'temp_ela.png'\n",
    "    \n",
    "    image = Image.open(path).convert('RGB')\n",
    "    image.save(temp_filename, 'JPEG', quality = quality)\n",
    "    temp_image = Image.open(temp_filename)\n",
    "    \n",
    "    ela_image = ImageChops.difference(image, temp_image)\n",
    "    \n",
    "    extrema = ela_image.getextrema()\n",
    "    max_diff = max([ex[1] for ex in extrema])\n",
    "    if max_diff == 0:\n",
    "        max_diff = 1\n",
    "    scale = 255.0 / max_diff\n",
    "    \n",
    "    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
    "    \n",
    "    return ela_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 224\n",
    "w = 224\n",
    "image_size = (h, w)\n",
    "\n",
    "np_arr = lambda img: np.array(img.resize(image_size)).flatten() / 255.0\n",
    "\n",
    "def prepare_image(image_path):\n",
    "    return np_arr(convert_to_ela_image(image_path, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # ELA converted images\n",
    "Y = [] # 0 for fake, 1 for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(path, cls):\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('jpg') or filename.endswith('png'):\n",
    "                try:\n",
    "                    full_path = os.path.join(dirname, filename)\n",
    "                    X.append(prepare_image(full_path))\n",
    "                    Y.append(cls)\n",
    "                except:\n",
    "                    pass\n",
    "                if len(Y) % 500 == 0:\n",
    "                    print('Processing {} images'.format(len(Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#place authentic\n",
    "Au_path = '../synthetic/Au'\n",
    "prepare_data(Au_path, 1)\n",
    "random.shuffle(X)\n",
    "print(len(X), len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#place tampered\n",
    "Tp_path = '../synthetic/Tp'\n",
    "prepare_data(Tp_path, 0)\n",
    "print(len(X), len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = to_categorical(Y, 2)\n",
    "X = X.reshape(-1, h, w, 3)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size = 0.2, random_state=5)\n",
    "\n",
    "X = X.reshape(-1,1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(h, w, 3))\n",
    "x = Conv2D(32, 3, padding='valid', activation='relu')(input)\n",
    "x = Conv2D(32, 3, padding='valid', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "# x = Dropout(0.25)(x)\n",
    "\n",
    "x = Conv2D(32, 3, padding='valid', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(32, 3, padding='valid', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "# x = Dropout(0.25)(x)\n",
    "\n",
    "# x = Conv2D(64, 3, padding='valid', activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Conv2D(64, 3, padding='valid', activation='relu')(x)\n",
    "# x = MaxPool2D(pool_size=2)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "\n",
    "# x = Conv2D(256, 3, padding='valid', activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Conv2D(256, 3, padding='valid', activation='relu')(x)\n",
    "# x = MaxPool2D(pool_size=2)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "\n",
    "# x = Conv2D(512, 3, padding='valid', activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Conv2D(512, 3, padding='valid', activation='relu')(x)\n",
    "# x = MaxPool2D(pool_size=2)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 32\n",
    "init_lr = 1e-4\n",
    "# optimizer = Adam(lr = init_lr)\n",
    "optimizer = Adam(lr = init_lr, decay = init_lr/epochs)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0,patience=3, verbose=0, mode='auto')\n",
    "\n",
    "checkpoint_filepath = 'ela_synthetic/checkpoint'\n",
    "model_checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True, monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val), callbacks=[early_stopping, model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_set = [] # SRM converted images\n",
    "Y_test_set = [] # 0 for fake, 1 for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(path, cls):\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('jpg') or filename.endswith('png'):\n",
    "                try:\n",
    "                    full_path = os.path.join(dirname, filename)\n",
    "                    X_test_set.append(prepare_image(full_path))\n",
    "                    Y_test_set.append(cls)\n",
    "                except:\n",
    "                    pass\n",
    "                if len(Y_test_set) % 500 == 0:\n",
    "                    print('Processing {} images'.format(len(Y_test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#place authentic\n",
    "# synthetic_test/Au\n",
    "Au_path = '../synthetic_test/Au'\n",
    "prepare_data(Au_path, 1)\n",
    "random.shuffle(X_test_set)\n",
    "# X = X[:2100]\n",
    "# Y = Y[:2100]\n",
    "print(len(X_test_set), len(Y_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#place tampered\n",
    "Tp_path = '../synthetic_test/Tp'\n",
    "prepare_data(Tp_path, 0)\n",
    "print(len(X_test_set), len(Y_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_set = np.array(X_test_set)\n",
    "Y_test_set = to_categorical(Y_test_set, 2)\n",
    "X_test_set = X_test_set.reshape(-1, h, w, 3)\n",
    "\n",
    "x_test, x_test2, y_test, y_test2 = train_test_split(X_test_set, Y_test_set, test_size = 0.2, random_state=5)\n",
    "\n",
    "# X_test = X_test.reshape(-1,1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "average_precision = average_precision_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(\"acc.png\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_1 = model.load_weights('srm_synthetic_7/checkpoint.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_1.predict(x_test)\n",
    "average_precision = average_precision_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.12xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/tensorflow-2.3-gpu-py37-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}