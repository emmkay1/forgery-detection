{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.4.1-cp37-cp37m-manylinux1_x86_64.whl (10.3 MB)\n",
      "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/site-packages (from matplotlib) (1.18.5)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/site-packages (from matplotlib) (7.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "Installing collected packages: kiwisolver, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.4.1\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May  5 00:40:57 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:1B.0 Off |                    0 |\n",
      "| N/A   28C    P0    26W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla T4            Off  | 00000000:00:1C.0 Off |                    0 |\n",
      "| N/A   30C    P0    25W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla T4            Off  | 00000000:00:1D.0 Off |                    0 |\n",
      "| N/A   29C    P0    25W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla T4            Off  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   29C    P0    19W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Input\n",
    "# import tf_slim as slim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import os\n",
    "import itertools\n",
    "import random\n",
    "%matplotlib inline\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ela_image(path, quality):\n",
    "    temp_filename = 'temp_file_name.jpg'\n",
    "    ela_filename = 'temp_ela.png'\n",
    "    \n",
    "    image = Image.open(path).convert('RGB')\n",
    "    image.save(temp_filename, 'JPEG', quality = quality)\n",
    "    temp_image = Image.open(temp_filename)\n",
    "    \n",
    "    ela_image = ImageChops.difference(image, temp_image)\n",
    "    \n",
    "    extrema = ela_image.getextrema()\n",
    "    max_diff = max([ex[1] for ex in extrema])\n",
    "    if max_diff == 0:\n",
    "        max_diff = 1\n",
    "    scale = 255.0 / max_diff\n",
    "    \n",
    "    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
    "    \n",
    "    return ela_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 224\n",
    "w = 224\n",
    "image_size = (h, w)\n",
    "\n",
    "np_arr = lambda img: np.array(img.resize(image_size)).flatten() / 255.0\n",
    "\n",
    "def prepare_image(image_path):\n",
    "    return np_arr(convert_to_ela_image(image_path, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] # ELA converted images\n",
    "Y = [] # 0 for fake, 1 for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(path, cls):\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('jpg') or filename.endswith('png'):\n",
    "                try:\n",
    "                    full_path = os.path.join(dirname, filename)\n",
    "                    X.append(prepare_image(full_path))\n",
    "                    Y.append(cls)\n",
    "                except:\n",
    "                    pass\n",
    "                if len(Y) % 500 == 0:\n",
    "                    print('Processing {} images'.format(len(Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 500 images\n",
      "Processing 1000 images\n",
      "Processing 1500 images\n",
      "Processing 2000 images\n",
      "Processing 2500 images\n",
      "Processing 3000 images\n",
      "Processing 3500 images\n",
      "Processing 4000 images\n",
      "Processing 4500 images\n",
      "Processing 5000 images\n",
      "Processing 5500 images\n",
      "Processing 6000 images\n",
      "Processing 6500 images\n",
      "Processing 7000 images\n",
      "Processing 7500 images\n",
      "Processing 8000 images\n",
      "8173 8173\n"
     ]
    }
   ],
   "source": [
    "#place authentic\n",
    "Au_path = '../synthetic/Au'\n",
    "prepare_data(Au_path, 1)\n",
    "random.shuffle(X)\n",
    "print(len(X), len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 8500 images\n",
      "Processing 9000 images\n",
      "Processing 9500 images\n",
      "Processing 10000 images\n",
      "Processing 10500 images\n",
      "Processing 11000 images\n",
      "Processing 11500 images\n",
      "Processing 12000 images\n",
      "12477 12477\n"
     ]
    }
   ],
   "source": [
    "#place tampered\n",
    "Tp_path = '../synthetic/Tp'\n",
    "prepare_data(Tp_path, 0)\n",
    "print(len(X), len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = to_categorical(Y, 2)\n",
    "X = X.reshape(-1, h, w, 3)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size = 0.2, random_state=5)\n",
    "\n",
    "X = X.reshape(-1,1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 220, 220, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 110, 110, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 108, 108, 32)      9248      \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 106, 106, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 53, 53, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 53, 53, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 89888)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               23011584  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 23,040,738\n",
      "Trainable params: 23,040,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(h, w, 3))\n",
    "x = Conv2D(32, 3, padding='valid', activation='relu')(input)\n",
    "x = Conv2D(32, 3, padding='valid', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "# x = Dropout(0.25)(x)\n",
    "\n",
    "x = Conv2D(32, 3, padding='valid', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(32, 3, padding='valid', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size=2)(x)\n",
    "x = BatchNormalization()(x)\n",
    "# x = Dropout(0.25)(x)\n",
    "\n",
    "# x = Conv2D(64, 3, padding='valid', activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Conv2D(64, 3, padding='valid', activation='relu')(x)\n",
    "# x = MaxPool2D(pool_size=2)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "\n",
    "# x = Conv2D(256, 3, padding='valid', activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Conv2D(256, 3, padding='valid', activation='relu')(x)\n",
    "# x = MaxPool2D(pool_size=2)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "\n",
    "# x = Conv2D(512, 3, padding='valid', activation='relu')(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Conv2D(512, 3, padding='valid', activation='relu')(x)\n",
    "# x = MaxPool2D(pool_size=2)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "output = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 32\n",
    "init_lr = 1e-4\n",
    "# optimizer = Adam(lr = init_lr)\n",
    "optimizer = Adam(lr = init_lr, decay = init_lr/epochs)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0,patience=3, verbose=0, mode='auto')\n",
    "\n",
    "checkpoint_filepath = 'ela_synthetic/checkpoint'\n",
    "model_checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True, monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "\n",
    "model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  2/312 [..............................] - ETA: 14s - loss: 0.6897 - accuracy: 0.6094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0286s vs `on_train_batch_end` time: 0.0614s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0286s vs `on_train_batch_end` time: 0.0614s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - ETA: 0s - loss: 0.5900 - accuracy: 0.6994WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0061s vs `on_test_batch_end` time: 0.0124s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0061s vs `on_test_batch_end` time: 0.0124s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312/312 [==============================] - 30s 95ms/step - loss: 0.5900 - accuracy: 0.6994 - val_loss: 0.5759 - val_accuracy: 0.7240\n",
      "Epoch 2/50\n",
      "312/312 [==============================] - 25s 81ms/step - loss: 0.5093 - accuracy: 0.7873 - val_loss: 0.5984 - val_accuracy: 0.6783\n",
      "Epoch 3/50\n",
      "312/312 [==============================] - 25s 81ms/step - loss: 0.4765 - accuracy: 0.8062 - val_loss: 0.6110 - val_accuracy: 0.6871\n",
      "Epoch 4/50\n",
      "312/312 [==============================] - 28s 90ms/step - loss: 0.4700 - accuracy: 0.8018 - val_loss: 0.4769 - val_accuracy: 0.8049\n",
      "Epoch 5/50\n",
      "312/312 [==============================] - 25s 82ms/step - loss: 0.4507 - accuracy: 0.8169 - val_loss: 0.4928 - val_accuracy: 0.7833\n",
      "Epoch 6/50\n",
      "312/312 [==============================] - 26s 82ms/step - loss: 0.4451 - accuracy: 0.8153 - val_loss: 0.4870 - val_accuracy: 0.7905\n",
      "Epoch 7/50\n",
      "312/312 [==============================] - 26s 83ms/step - loss: 0.4220 - accuracy: 0.8301 - val_loss: 0.5071 - val_accuracy: 0.7853\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_val, y_val), callbacks=[early_stopping, model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_set = [] # SRM converted images\n",
    "Y_test_set = [] # 0 for fake, 1 for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(path, cls):\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('jpg') or filename.endswith('png'):\n",
    "                try:\n",
    "                    full_path = os.path.join(dirname, filename)\n",
    "                    X_test_set.append(prepare_image(full_path))\n",
    "                    Y_test_set.append(cls)\n",
    "                except:\n",
    "                    pass\n",
    "                if len(Y_test_set) % 500 == 0:\n",
    "                    print('Processing {} images'.format(len(Y_test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 500 images\n",
      "790 790\n"
     ]
    }
   ],
   "source": [
    "#place authentic\n",
    "# synthetic_test/Au\n",
    "Au_path = '../synthetic_test/Au'\n",
    "prepare_data(Au_path, 1)\n",
    "random.shuffle(X_test_set)\n",
    "# X = X[:2100]\n",
    "# Y = Y[:2100]\n",
    "print(len(X_test_set), len(Y_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1000 images\n",
      "1190 1190\n"
     ]
    }
   ],
   "source": [
    "#place tampered\n",
    "Tp_path = '../synthetic_test/Tp'\n",
    "prepare_data(Tp_path, 0)\n",
    "print(len(X_test_set), len(Y_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_set = np.array(X_test_set)\n",
    "Y_test_set = to_categorical(Y_test_set, 2)\n",
    "X_test_set = X_test_set.reshape(-1, h, w, 3)\n",
    "\n",
    "x_test, x_test2, y_test, y_test2 = train_test_split(X_test_set, Y_test_set, test_size = 0.2, random_state=5)\n",
    "\n",
    "# X_test = X_test.reshape(-1,1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "average_precision = average_precision_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8482920680193418"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.savefig(\"acc.png\", bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model_1 = model.load_weights('srm_synthetic_7/checkpoint.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-42ec3bbbc2bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0maverage_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "predictions = model_1.predict(x_test)\n",
    "average_precision = average_precision_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.12xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/tensorflow-2.3-gpu-py37-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
